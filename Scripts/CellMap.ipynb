{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellMap Tutorial\n",
    "\n",
    "This [notebook](CellMap.ipynb) is a tutorial to run the main processing script that qunatfies immediate early gene expression from lightsheet data of iDISCO+ ceared brains."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The source for this notebook can be found here: \n",
    "<a class=\"reference download internal\" download=\"\" href=\"CellMap.ipynb\">\n",
    "    <code class=\"xref download docutils literal notranslate\"><span class=\"pre\">CellMap.ipynb</span></code></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__    = 'Christoph Kirst <christoph.kirst.ck@gmail.com>'\n",
    "__license__   = 'GPLv3 - GNU General Pulic License v3 (see LICENSE)'\n",
    "__copyright__ = 'Copyright © 2020 by Christoph Kirst'\n",
    "__webpage__   = 'http://idisco.info'\n",
    "__download__  = 'http://www.github.com/ChristophKirst/ClearMap2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ClearMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastix sucessfully initialized from path: /home/ckirst/Programs/ClearMap2/ClearMap/External/elastix/build\n"
     ]
    }
   ],
   "source": [
    "#ClearMap path\n",
    "import sys\n",
    "sys.path.append('/home/ckirst/Programs/ClearMap2')\n",
    "\n",
    "#load ClearMap modules\n",
    "from ClearMap.Environment import *  #analysis:ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "    \n",
    "As ClearMap compiles its code on demand, executing this for the first time may take 5-30min.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize workspace\n",
    "\n",
    "The following sets up the directories and filenames for a CellMap project. \n",
    "\n",
    "The raw files and files generated during the analysis of a data set are managed via the [workspace](Api/ClearMap.IO.Workspace.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace[CellMap]{/home/ckirst/Programs/ClearMap2/ClearMap/Tests/Data/CellMap_Example}\n",
      "              raw: Raw/Fos/Z<Z,4>.tif {402 files, ('Z',): (451,) -> (852,)}\n",
      " autofluorescence: no file\n",
      "         stitched: no file\n",
      "           layout: no file\n",
      "       background: no file\n",
      "        resampled: no file\n",
      "resampled_to_auto: no file\n",
      "auto_to_reference: no file\n",
      "            cells: no file\n",
      "          density: no file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#directories and files\n",
    "directory = '/home/ckirst/Programs/ClearMap2/ClearMap/Tests/Data/CellMap_Example'    \n",
    "\n",
    "expression_raw      = 'Raw/Fos/Z<Z,4>.tif'           \n",
    "expression_auto     = 'Autofluorescence/Auto/Z<Z,4>.tif'  \n",
    "\n",
    "ws = wsp.Workspace('CellMap', directory=directory);\n",
    "ws.update(raw=expression_raw, autofluorescence=expression_auto)\n",
    "ws.debug = False\n",
    "\n",
    "resources_directory = settings.resources_path\n",
    "\n",
    "ws.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of existing files in the project. As the project is new, only the raw data files and the autofluorescence images exist. \n",
    "\n",
    "* `directory` refers to the folder where the project data are located, and where all results will be written.\n",
    "\n",
    "\n",
    "* `expression_raw` refers to the source files for the raw data. It can be just a singe file name if the data is stored in a single file. If the raw data comes as a list of files, this can be an [TagExpression](Api/ClearMap.Utils.TagExpression.rst) of the file names.\n",
    "\n",
    "  For example, if the files written by the microscope are `Z0001.tif`, `Z0002.tif`, etc, where the number refers to the plane of a the stack those files can be used together as aa common source using a tag expression `Z<Z,4>.tif`. \n",
    "\n",
    "  A tag is a place holder for a number or a name and has the general form `<Name, Type, Width>` (see [TagExpression](Api/ClearMap.Utils.TagExpression.rst), and if `Type` is obmitted the tag is assumed to be digits. `Name` is the name of the tag and `Width` the number of chars or digits.\n",
    "\n",
    "  Here we use <Z,4> to denote that the images are numbered along the z-axis and that there are 4 digist with trailing zeros that number the images.\n",
    "\n",
    "* `expression_auto` refers to the autofluorescence channel acquisition. It is handled the same way as `expression_raw`.\n",
    "   \n",
    "   <div class=\"alert alert-info\">\n",
    "   Tip\n",
    "    \n",
    "   You don’t have to type in the complete filenames yourself! In Linux Ubuntu, you can click on the file whose path you want to get in the file explorer and ‘copy’ (`ctrl + c`), and then go back on the script and ‘paste’ (`ctrl + v`), and the full path of the file will be put in.\n",
    "   </div>\n",
    "       \n",
    "\n",
    "<div class=\"alert alert-info\">  \n",
    "Note\n",
    "    \n",
    "All file specificatoins are with respect to the working directory, which is automatically added to all paths.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize alignment \n",
    "\n",
    "First initialize the atlas reference files by roughly slicing them to the part of the brain under consideration. \n",
    "E.g. here our data set is half a brain and we slice the corresponding hemis-shpere from the refernece atlas.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "\n",
    "It is important that the alignment template and annotation file match the field of view of your acquisition. By default, they cover the whole brain, but if you acquired a smaller region of the brain (for instance only one hemisphere), you need to prepare new versions of these files to match the coverage of the brain from your acquisition. Also, the orientation in space of these images in these files needs to match the orientation of the brain during your acquisition. The original file themselves are located in the 'ClearMap/Ressources/Atlas’ folder and cropped files will be stored there as well.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: '/home/ckirst/Programs/ClearMap2/ClearMap/Resources/Atlas/ABA_25um_annotation__1_-2_3__slice_None_None_None__slice_None_None_None__slice_0_256_None__.tif'\n",
      "Preparing: '/home/ckirst/Programs/ClearMap2/ClearMap/Resources/Atlas/ABA_25um_reference__1_-2_3__slice_None_None_None__slice_None_None_None__slice_0_256_None__.tif'\n",
      "Preparing: '/home/ckirst/Programs/ClearMap2/ClearMap/Resources/Atlas/ABA_25um_distance_to_surface__1_-2_3__slice_None_None_None__slice_None_None_None__slice_0_256_None__.tif'\n"
     ]
    }
   ],
   "source": [
    "#init atals and reference files\n",
    "annotation_file, reference_file, distance_file=ano.prepare_annotation_files(\n",
    "    slicing=(slice(None),slice(None),slice(0,256)), orientation=(1,-2,3),\n",
    "    overwrite=False, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialize the parameter files to be used for the alignmnet via elastix.\n",
    "We provide a template files in ClearMap that typically dont need to be modified unless you \n",
    "experience problems with the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alignment parameter files    \n",
    "align_channels_affine_file   = io.join(resources_directory, 'Alignment/align_affine.txt')\n",
    "align_reference_affine_file  = io.join(resources_directory, 'Alignment/align_affine.txt')\n",
    "align_reference_bspline_file = io.join(resources_directory, 'Alignment/align_bspline.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you eed to stitch tiled data sets please refer to the [Stitching](TubeMap.ipynb#Stitching) section in the [TubeMap tutorial](TubeMap.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "*ClearMap* comes with a many tools to visualize the data ([Visualization](Api/ClearMap.Visualization.rst))\n",
    "\n",
    "To visualize 3d image data ClearMap provides a data explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7fb74acd6a50>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3d.plot(ws.filename('raw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ClearMap's* data viewer opens in a new window alowing you to inspect the data:\n",
    "\n",
    "![DataViewer](Static/CellMap_raw.jpg)\n",
    "\n",
    "\n",
    "You can also open more files at the same time with synchronized windows to inspect them simultaneously. \n",
    "For this, pass a list of files to the plot command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also overlay several files by specfying a inner list of files to overlay in a single window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7fb73ca63690>,\n",
       " <ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7fb73c977370>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3d.plot(ws.file_list('raw')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7fb73c918730>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3d.plot([ws.file_list('raw')[0:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataViewer Overlay](Static/CellMap_overlay.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "\n",
    "In order to open nmpy binary files with [ImageJ](https://imagej.net/Fiji) you ClearMap can write a mhd header using the function `write_header_from_source` in the [MHD module](Api/ClearMap.IO.MHD.rst) and opening this header file in [ImageJ](https://imagej.net/Fiji).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ckirst/Programs/ClearMap2/ClearMap/Tests/Data/CellMap_Example/stitched.npy.mhd'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.mhd.write_header_from_source(ws.filename('stitched'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching\n",
    "\n",
    "Stitching can be done using *ClearMap's* [WobblyStitcher](wobblystitcher.rst).\n",
    "\n",
    "You can refer to the [Stitching section](TubeMap.ipynb#Stitching) in the [TubeMap tutorial](TubeMap.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion\n",
    "\n",
    "To speed up processing it can be usefull to first convert the microscope data to a numpy binary file.\n",
    "This step is not neccesary though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Convet raw data to npy file     \n",
    "             \n",
    "source = ws.source('raw');\n",
    "sink   = ws.filename('stitched')\n",
    "io.convert(source, sink, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume you either stiched the data or converted it and use the `ws.filename('stitched')` for the raw data in the folllowing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and atlas alignment \n",
    "\n",
    "Here we will align the scan with the reference atlas. As mentioned before, make sure the template\n",
    "and annotation files are in the same orientation as the brain scan, and that their field of view \n",
    "covers more or less the same regions.\n",
    "\n",
    "\n",
    "### Resampling - raw data\n",
    "\n",
    "In the resampling and alignment step, there are only a few parameters to check:\n",
    "\n",
    "* `source_resolution` is the resolution of the data as `(x-resolution, y-resolution, z-resolution)`. \n",
    "\n",
    "   \n",
    "* `sink-resolution` is the resolution of the Atlas. We use the 25µm version of the annotation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_parameter = {\n",
    "    \"source_resolution\" : (1.625,1.625,1.6),\n",
    "    \"sink_resolution\"   : (25,25,25),\n",
    "    \"processes\" : None,\n",
    "    \"verbose\" : True,             \n",
    "    };\n",
    "\n",
    "res.resample(ws.filename('stitched'), sink=ws.filename('resampled'), **resample_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling - autofluorescence\n",
    "\n",
    "* `source_resolution` refers to the autofluorescence scan. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  resample_parameter_auto = {\n",
    "    \"source_resolution\" : (5,5,6),\n",
    "    \"sink_resolution\"   : (25,25,25),\n",
    "    \"processes\" : None,\n",
    "    \"verbose\" : True,                \n",
    "    };    \n",
    "\n",
    "res.resample(ws.filename('autofluorescence'), \n",
    "             sink=ws.filename('resampled', postfix='autofluorescence'), \n",
    "             **resample_parameter_auto)\n",
    "\n",
    "#p3d.plot([ws.filename('resampled'), ws.filename('resampled', postfix='autofluorescence')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the orientation of the sample has to be set to match the orientation of the Atlas reference files. It is not mandatory to acquire the sample in the same orientation as the atlas. For instance, you can acquire the left side of the brain, and map it onto the right side of the atlas by adding `\"orientation\":(1,2,3)`\n",
    "to the `resample_parameter`. \n",
    "\n",
    "The numbers indicate the axes order starting from 1 to d and a negative axis number indicates reversal of that axis. E.g.:\n",
    "\n",
    "|Orientation        |Description\n",
    "|:------------------|:-------------------------------------------------------\n",
    "|(1, 2, 3)          |The scan has the same orientation as the atlas reference\n",
    "|(-1, 2, 3)         |The x axis is inverted compared to the atlas\n",
    "|(1, -2, 3)         |The y axis is inverted compared to the atlas\n",
    "|(2, 1, 3)          |Exchanges the x and y axis\n",
    "|(3, 2, -1)         |Exchanges the z and x axis and inverts the new z-axis.\n",
    "\n",
    "\n",
    "For our samples, we use the following orientation to match our atlas files:\n",
    "\n",
    "* The right side of the brain is facing the objective, lateral side up.\n",
    "\n",
    "* The rostral side of the brain is up\n",
    "\n",
    "* The dorsal side is facing left\n",
    "\n",
    "* The ventral side is facing right\n",
    "\n",
    "In this situation, if we want to image the right hemisphere, we use (1, 2, 3) and if we want to image the left hemisphere, we use (-1, 2, 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment  - resampled to autofluorescence\n",
    "\n",
    "This step interfaces to [elastix](https://elastix.lumc.nl/) to aligin the resampled raw image to the resampled autofluorescence image.\n",
    "\n",
    "As the autofluorescence image is often taken in a separate step with different microscope settings both images typically do not align. This steps corrects for this via a affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the two channels\n",
    "align_channels_parameter = {            \n",
    "    #moving and reference images\n",
    "    \"moving_image\" : ws.filename('resampled', postfix='autofluorescence'),\n",
    "    \"fixed_image\"  : ws.filename('resampled'),\n",
    "    \n",
    "    #elastix parameter files for alignment\n",
    "    \"affine_parameter_file\"  : align_channels_affine_file,\n",
    "    \"bspline_parameter_file\" : None,\n",
    "    \n",
    "    #directory of the alig'/home/nicolas.renier/Documents/ClearMap_Ressources/Par0000affine.txt',nment result\n",
    "    \"result_directory\" :  ws.filename('elastix_resampled_to_auto')\n",
    "    }; \n",
    "\n",
    "elx.align(**align_channels_parameter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment - autofluorescence to reference\n",
    "\n",
    "This step aligins the resampled autofluorescence image to the atlas reference via a non-linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align autofluorescence to reference\n",
    "align_reference_parameter = {            \n",
    "    #moving and reference images\n",
    "    \"moving_image\" : reference_file,\n",
    "    \"fixed_image\"  : ws.filename('resampled', postfix='autofluorescence'),\n",
    "    \n",
    "    #elastix parameter files for alignment\n",
    "    \"affine_parameter_file\"  :  align_reference_affine_file,\n",
    "    \"bspline_parameter_file\" :  align_reference_bspline_file,\n",
    "    #directory of the alignment result\n",
    "    \"result_directory\" :  ws.filename('elastix_auto_to_reference')\n",
    "    };\n",
    "\n",
    "elx.align(**align_reference_parameter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alignment step should last for about 2 to 10 minutes and generate two files: \n",
    "`ws.filename('resampled')` and `ws.filename('resampled', postfix='autofluorescence'))`, as well as 2 folders: `elastix_resampled_to_auto` and `elastix_auto_to_reference`. \n",
    "\n",
    "You can check the quality of the alignment. The easiest is to use [Fiji (Image J)](https://imagej.net/Fiji). Open the following files: `ws.filename('resampled')` and `ws.filename('resampled', postfix='autofluorescence'))`. These are the original we need to align. \n",
    "\n",
    "Then go into the `elastix_resampled_to_auto` folder. This is the alignment of the resampled data to the resampled autofluorescence image. Open the `result.0.mhd` file. \n",
    "\n",
    "Then go to the folder `elastix_auto_to_reference`. This is the result of the alignment of the autofluorescence to the Atlas reference. Open the `result.1.mhd file`. \n",
    "\n",
    "Organize the files as follows: \n",
    "\n",
    "![Alignment check](Static/Alignment_check.png)\n",
    "\n",
    "You can find the contrast adjustment panel in `Image -> Adjust -> Brightness/Contrast`. The synchronize windows tool can be found in `Analyze -> Tools -> Synchronize windows`. Click on `Synchronize all`, and travel through the stacks. With the mouse pointer, and make sure each aligned stack are well in sync with each other: make sure the outline of the brain is aligned, as well as the internal structures. Only the aligned data (images organized vertically here) have to match. If the alignment is good, you are then ready for the image processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data\n",
    "\n",
    "This optional step allows to create a smaller sub-image from the full image in order to test the image processing\n",
    "pipeline that follows.\n",
    "\n",
    "When starting with a new data set, we highly recommend using this step to speed up processing and \n",
    "adjust the pipeline.\n",
    "\n",
    "Skip this if you dont need to test the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Crop test data \n",
    "\n",
    "#select sublice for testing the pipeline\n",
    "slicing = (slice(2000,2200),slice(2000,2200),slice(50,80));\n",
    "ws.create_debug('stitched', slicing=slicing);\n",
    "ws.debug = True; \n",
    "\n",
    "#p3d.plot(ws.filename('stitched'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like to create various test sets you can give each subset a name by setting `ws.debug = 'name_for_the_test_subset'` in the above code and run it again. \n",
    "\n",
    "You can switch between test sets by using `ws.debug = 'name_for_the_test_subset'`\n",
    "\n",
    "Once the pipeline is performing well, you can swtich to run it on the full data by setting `ws.debug = False`\n",
    "\n",
    "You can see the effect of the debug mode on the filenames here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stitched.npy\n",
      "debug_stitched.npy\n",
      "test_stitched.npy\n"
     ]
    }
   ],
   "source": [
    "debug = ws.debug;\n",
    "ws.debug = False\n",
    "print(ws.filename('stitched', directory=False))\n",
    "ws.debug = True\n",
    "print(ws.filename('stitched', directory=False))\n",
    "ws.debug = 'test'\n",
    "print(ws.filename('stitched', directory=False))\n",
    "ws.debug = debug;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell detection\n",
    "\n",
    "The next step is to detect the cells in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 blocks with function 'detect_cells_block'.\n",
      "Processing block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Background removal shape: (7, 7)\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Background removal form : Disk\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Background removal save : False\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Illumination correction: elapsed time: 0:00:00.042\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: DoG filter: shape : None\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: DoG filter: sigma : None\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: DoG filter: sigma2: None\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: DoG filter: elapsed time: 0:00:00.000\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Maxima detection: h_max    : None\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Maxima detection: shape    : 5\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Maxima detection: threshold: 0\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Maxima detection: save     : /home/ckirst/Programs/ClearMap2/ClearMap/Tests/Data/CellMap_Example/debug_cells_maxima.npy\n",
      "Find Maxima: h_max    : None\n",
      "Find Maxima: shape    : 5\n",
      "Find Maxima: threshold: 0\n",
      "Find Maxima: elapsed time: 0:00:00.049\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Maxima detection: elapsed time: 0:00:00.065\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Shape detection: threshold: 500\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Shape detection: save     : False\n",
      "Shape detection threshold: 500\n",
      "Shape detection: elapsed time: 0:00:00.221\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Shape detection: elapsed time: 0:00:00.337\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Intensity detection: method: max\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Intensity detection: shape : 3\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Shape detection: elapsed time: 0:00:00.031\n",
      "Block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: Cell detection: elapsed time: 0:00:00.478\n",
      "Processing block 0/1<(0, 0, 0)/(1, 1, 1)> (200, 200, 30)@(200, 200, 30)[(:,:,0:30)]: elapsed time: 0:00:00.536\n",
      "Processed 1 blocks with function 'detect_cells_block': elapsed time: 0:00:00.599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ckirst/Programs/ClearMap2/ClearMap/Tests/Data/CellMap_Example/debug_cells_raw.npy'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Cell detection:\n",
    "\n",
    "cell_detection_parameter = cells.default_cell_detection_parameter.copy();\n",
    "cell_detection_parameter['illumination'] = None;\n",
    "cell_detection_parameter['background'] = None;\n",
    "cell_detection_parameter['intensity_detection']['measure'] = ['source'];\n",
    "cell_detection_parameter['shape_detection']['threshold'] = 500;\n",
    "\n",
    "io.delete_file(ws.filename('cells', postfix='maxima'))\n",
    "cell_detection_parameter['maxima_detection']['save'] = ws.filename('cells', postfix='maxima')\n",
    "\n",
    "processing_parameter = cells.default_cell_detection_processing_parameter.copy();\n",
    "processing_parameter.update(\n",
    "    processes = 'serial',\n",
    "    size_max = 100, #35,\n",
    "    size_min = 30, #30,\n",
    "    overlap  = 32, #10,\n",
    "    verbose = True\n",
    "    )\n",
    "\n",
    "cells.detect_cells(ws.filename('stitched'), ws.filename('cells', postfix='raw'),\n",
    "                   cell_detection_parameter=cell_detection_parameter, \n",
    "                   processing_parameter=processing_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively this function performs the following steps:\n",
    "\n",
    "* [illumination correction](#Illumination-correction)\n",
    "\n",
    "* [background removal](#Background-removal)\n",
    "\n",
    "* [equalization](#Equalization)\n",
    "\n",
    "* [difference of Gaussians (DoG) filter](#DoG-Filter)\n",
    "\n",
    "* [maxima detection](#Maxima-detection)\n",
    "\n",
    "* [cell shape detection](#Shape-detection)\n",
    "\n",
    "* [cell intensity measurements](#Intensity-detection)\n",
    "    \n",
    "  \n",
    "The parameters for each step are passed as sub-dictionaries to the `cell_detection_parameter` dictionary:\n",
    "  \n",
    "* If None is passed for one of the steps this step is skipped.\n",
    "  \n",
    "* Each step also has an additional parameter `save` that enables saving of \n",
    "  the result of that step to a file to inspect the pipeline.\n",
    "\n",
    "The details can be found [here](Api/ClearMap.ImageProcessing.Experts.Cells.rst).\n",
    "\n",
    "Lets look at the default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iullumination_correction: dict\n",
      "                          flatfield: None\n",
      "                          scaling  : mean\n",
      "background_correction   : dict\n",
      "                          shape: (7, 7)\n",
      "                          form : Disk\n",
      "                          save : False\n",
      "equalization            : None\n",
      "dog_filter              : dict\n",
      "                          shape : None\n",
      "                          sigma : None\n",
      "                          sigma2: None\n",
      "maxima_detection        : dict\n",
      "                          h_max    : None\n",
      "                          shape    : 5\n",
      "                          threshold: 0\n",
      "                          save     : False\n",
      "shape_detection         : dict\n",
      "                          threshold: 700\n",
      "                          save     : False\n",
      "intensity_detection     : dict\n",
      "                          method : max\n",
      "                          shape  : 3\n",
      "                          measure: ['source', 'background']\n"
     ]
    }
   ],
   "source": [
    "import ClearMap.Utils.HierarchicalDict as hdict\n",
    "hdict.pprint(cells.default_cell_detection_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loist the parameters for this step:\n",
    "\n",
    "### Illumination correction\n",
    " \n",
    "Illumination correction step parameter are set by the `illumincation_correction` dict using\n",
    "\n",
    "* `flatfield` : array or str \n",
    "      The flat field estimate for the image planes.\n",
    "\n",
    "* `background` : array or None\n",
    "      A background level to assume for the flatfield correction.\n",
    "\n",
    "* `scaling` : float, 'max', 'mean' or None\n",
    "      Optional scaling after the flat field correction.\n",
    "\n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    " \n",
    " \n",
    "### Background removal\n",
    "\n",
    "`background_correction` : dict or None\n",
    "\n",
    "* `shape` : tuple\n",
    "      The shape of the structure lement to estimate the background.\n",
    "      This should be larger than the typical cell size.\n",
    "\n",
    "* `form` : str\n",
    "      The form of the structur element (e.g. 'Disk')\n",
    "\n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    "  \n",
    "\n",
    "### Equalization\n",
    "\n",
    "`equalization` : dict or None\n",
    "\n",
    "* `precentile` : tuple\n",
    "      The lower and upper percentiles used to estimate the equalization.\n",
    "      The lower percentile is used for normalization, the upper to limit the\n",
    "      maximal boost to a maximal intensity above this percentile.\n",
    "\n",
    "* `max_value` : float\n",
    "      The maximal intensity value in the equalized image.\n",
    "\n",
    "* `selem` : tuple\n",
    "      The structural element size to estimate the percentiles. \n",
    "      Should be larger than the larger vessels.\n",
    "\n",
    "* `spacing` : tuple\n",
    "      The spacing used to move the structural elements.\n",
    "      Larger spacings speed up processing but become locally less precise.\n",
    "\n",
    "* `interpolate` : int\n",
    "      The order of the interpoltation used in constructing the full \n",
    "      background estimate in case a non-trivial spacing is used.\n",
    "\n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    "  \n",
    "  \n",
    "### DoG Filter\n",
    "\n",
    "`dog_filter` : dict or None\n",
    "   \n",
    "* `shape` : tuple\n",
    "      The shape of the filter.\n",
    "      This should be near the typical cell size.\n",
    "\n",
    "* `sigma` : tuple or None\n",
    "      The std of the inner Gaussian.\n",
    "      If None, detemined automatically from shape.\n",
    "\n",
    "* `sigma2` : tuple or None\n",
    "      The std of the outer Gaussian.\n",
    "      If None, detemined automatically from shape.\n",
    "\n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    "  \n",
    "  \n",
    "### Maxima detection\n",
    "\n",
    "`maxima_detection` : dict or None\n",
    " \n",
    "* `h_max` : float or None\n",
    "      The 'height'for the extended maxima.\n",
    "      If None, simple local maxima detection isused.\n",
    "\n",
    "* `shape` : tuple\n",
    "      The shape of the structural element for extended maxima detection.\n",
    "      This should be near the typical cell size.\n",
    "    \n",
    "* `threshold` : float or None\n",
    "      Only maxima above this threshold are detected. If None, all maxima\n",
    "      are detected.\n",
    "    \n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    "\n",
    "\n",
    "### Shape detection\n",
    "  \n",
    "`shape_detection` : dict or None\n",
    "\n",
    "* `threshold` : float\n",
    "      Cell shape is expanded from maxima if pixles are above this threshold\n",
    "      and not closer to another maxima.\n",
    "    \n",
    "* `save` : str or None\n",
    "      Save the result of this step to the specified file if not None.\n",
    " \n",
    " \n",
    "### Intensity detection\n",
    "\n",
    "`intensity_detection` : dict or None\n",
    "\n",
    "* `method` : {'max'|'min','mean'|'sum'}\n",
    "      The method to use to measure the intensity of a cell.\n",
    "      \n",
    "* `shape : tuple or None\n",
    "      If no cell shapes are detected a disk of this shape is used to measure\n",
    "      the cell intensity.\n",
    "    \n",
    "* `measure` : list of str\n",
    "      Here the steps fat which te measurement should be taken is specified.\n",
    "      E.g. to meausre the raw intensity use 'source', to measure the backround corected intensity use 'background'\n",
    "\n",
    "* `save : str or None\n",
    "      Save the result of this step to the specified file if not None.m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be visualized i different ways. \n",
    "\n",
    "We first overlay all unfiltered detected maxima (potnetial cell centers) with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7f52e87bed70>,\n",
       " <ClearMap.Visualization.Qt.DataViewer.DataViewer at 0x7f52e4cacb90>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3d.plot([source, sink])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will look something like\n",
    "\n",
    "![CellMap_maxima_unfiltered](Static/CellMap_maxima_unfiltered.png)\n",
    "\n",
    "where the green dots are the potential maxima.\n",
    "\n",
    "We can also plot the filtered maxima in 3d, though the validatoin of the results i stypically better done browsing through the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.hstack([ws.source('cells', postfix='raw')[c][:,None] for c in 'xyz']);\n",
    "p = p3d.list_plot_3d(coordinates)\n",
    "p3d.plot_3d(ws.filename('stitched'), view=p, cmap=p3d.grays_alpha(alpha=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CellMap_maxima_3d](Static/CellMap_maxima_3d.png)\n",
    "\n",
    "to adjust the parameter you can also plot some histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ws.source('cells', postfix='raw')\n",
    "\n",
    "plt.figure(1); plt.clf();\n",
    "names = source.dtype.names;\n",
    "nx,ny = p3d.subplot_tiling(len(names));\n",
    "for i, name in enumerate(names):\n",
    "  plt.subplot(nx, ny, i+1)\n",
    "  plt.hist(source[name]);\n",
    "  plt.title(name)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CellMap_histograms](Static/CellMap_histograms.png)\n",
    "\n",
    "using this you can futher filter the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#%% Filter cells\n",
    "\n",
    "thresholds = {\n",
    "    'source' : None,\n",
    "    'size'   : (20,None)\n",
    "    }\n",
    "\n",
    "cells.filter_cells(source = ws.filename('cells', postfix='raw'), \n",
    "                   sink = ws.filename('cells', postfix='filtered'), \n",
    "                   thresholds=thresholds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([ws.source('cells', postfix='filtered')[c] for c in 'xyz']).T;\n",
    "p = p3d.list_plot_3d(coordinates, color=(1,0,0,0.5), size=10)\n",
    "p3d.plot_3d(ws.filename('stitched'), view=p, cmap=p3d.grays_alpha(alpha=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CellMap_filtered_3d](Static/CellMap_filtered_3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas alignment and annotation\n",
    "\n",
    "Next we algin the cell coordinates to the atlas and use this to annotate the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell alignment\n",
    "\n",
    "source = ws.source('cells', postfix='filtered')\n",
    "\n",
    "def transformation(coordinates):\n",
    "  coordinates = res.resample_points(\n",
    "                  coordinates, sink=None, orientation=None, \n",
    "                  source_shape=io.shape(ws.filename('stitched')), \n",
    "                  sink_shape=io.shape(ws.filename('resampled')));\n",
    "  \n",
    "  coordinates = elx.transform_points(\n",
    "                  coordinates, sink=None, \n",
    "                  transform_directory=ws.filename('resampled_to_auto'), \n",
    "                  binary=True, indices=False);\n",
    "  \n",
    "  coordinates = elx.transform_points(\n",
    "                  coordinates, sink=None, \n",
    "                  transform_directory=ws.filename('auto_to_reference'),\n",
    "                  binary=True, indices=False);\n",
    "      \n",
    "  return coordinates;\n",
    "  \n",
    "\n",
    "coordinates = np.array([source[c] for c in 'xyz']).T;\n",
    "\n",
    "coordinates_transformed = transformation(coordinates);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell annotation\n",
    "\n",
    "label = ano.label_points(coordinates_transformed, key='order');\n",
    "names = ano.convert_label(label, key='order', value='name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save results\n",
    "\n",
    "coordinates_transformed.dtype=[(t,float) for t in ('xt','yt','zt')]\n",
    "label = np.array(label, dtype=[('order', int)]);\n",
    "names = np.array(names, dtype=[('name', 'a256')])\n",
    "\n",
    "import numpy.lib.recfunctions as rfn\n",
    "cells_data = rfn.merge_arrays([source[:], coordinates_transformed, label, names], flatten=True, usemask=False)\n",
    "\n",
    "io.write(ws.filename('cells'), cells_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We can  export this data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CSV export\n",
    "\n",
    "source = ws.source('cells');\n",
    "header = ', '.join([h[0] for h in source.dtype.names]);\n",
    "np.savetxt(ws.filename('cells', extension='csv'), source[:], header=header, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to work with files as generated by ClearMap1 you can use this export cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ClearMap1.0 export\n",
    "\n",
    "source = ws.source('cells');\n",
    "\n",
    "clearmap1_format = {'points' : ['x', 'y', 'z'], \n",
    "                    'points_transformed' : ['xt', 'yt', 'zt'],\n",
    "                    'intensities' : ['source', 'dog', 'background', 'size']}\n",
    "\n",
    "for filename, names in clearmap1_format.items():\n",
    "  sink = ws.filename('cells', postfix=['ClearMap1', filename]);\n",
    "  data = np.array([source[name] if name in source.dtype.names else np.full(source.shape[0], np.nan) for name in names]);\n",
    "  io.write(sink, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform analysis directly in ClearMap. The final section shows a simple example.\n",
    "\n",
    "### Voxelization - cell density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ws.source('cells')\n",
    "\n",
    "coordinates = np.array([source[n] for n in ['xt','yt','zt']]).T;\n",
    "intensities = source['source'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Unweighted \n",
    "\n",
    "voxelization_parameter = dict(\n",
    "      shape = io.shape(annotation_file), \n",
    "      dtype = None, \n",
    "      weights = None,\n",
    "      method = 'sphere', \n",
    "      radius = (7,7,7), \n",
    "      kernel = None, \n",
    "      processes = None, \n",
    "      verbose = True\n",
    "    )\n",
    "\n",
    "vox.voxelize(coordinates, sink=ws.filename('density', postfix='counts'), **voxelization_parameter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Weighted \n",
    "\n",
    "voxelization_parameter = dict(\n",
    "      shape = io.shape(annotation_file),\n",
    "      dtype = None, \n",
    "      weights = intensities,\n",
    "      method = 'sphere', \n",
    "      radius = (7,7,7), \n",
    "      kernel = None, \n",
    "      processes = None, \n",
    "      verbose = True\n",
    "    )\n",
    "\n",
    "vox.voxelize(points, sink=ws.filename('density', postfix='intensities'), **voxelization_parameter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "    \n",
    "You could also convert the data to a pandas DataFrame for further analysis. We tried to reduce the number of dependency packages for ClearMap and thus did not include this at this stage.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "\n",
    "Cell counts or intensities of each sample in considered regions or annotated\n",
    "brain areas between different groups can be compared using the independent\n",
    "two sample student t-test assuming unequal variances. \n",
    "\n",
    "ClearMap as a discovery tool also provides correction for p-values for multiple \n",
    "comparison to q-values to control for false-discovery rate \n",
    "\n",
    "See the :mod:`ClearMap.Analysis.Statistics` module for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
